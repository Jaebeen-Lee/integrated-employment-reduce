# -*- coding: utf-8 -*-
import streamlit as st
import os
try:
    from dotenv import load_dotenv
    try:
        load_dotenv()
    except Exception:
        pass
except Exception:
    pass

# ---------------------------------------------
# ì‹œë®¬ë ˆì´ì…˜ ë Œë” í•¨ìˆ˜ (ìš”ì•½ì´ ìˆìœ¼ë©´ í•­ìƒ í‘œ/ê²°ê³¼ í‘œì‹œ)


def _render_simulation_pane(params, size, region, clawback_method):
    """ìš”ì•½(gross/applied/years)ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ì‹œë®¬ë ˆì´ì…˜ í‘œ/ê²°ê³¼ë¥¼ ë Œë”ë§.
    - í‘œëŠ” ìµœì´ˆ 1íšŒë§Œ í˜„ì¬ ìš”ì•½ê°’(curr_total/curr_youth)ìœ¼ë¡œ ì´ˆê¸°í™”
    - ì‚¬ìš©ìê°€ í‘œë¥¼ í¸ì§‘í•´ë„ rerunì—ì„œ ìœ ì§€ (Enter ì‹œ ê°’ì´ ë˜ëŒì•„ê°€ì§€ ì•ŠìŒ)
    - í•„ìš” ì‹œ "í‘œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”" ë²„íŠ¼ìœ¼ë¡œë§Œ ì¬ì´ˆê¸°í™”
    """
    import pandas as _pd
    st.subheader("â‘¡ ì‚¬í›„ê´€ë¦¬(ì¶”ì§•) ì‹œë®¬ë ˆì´ì…˜ - ë‹¤ë…„í‘œ")

    if "summary" not in st.session_state:
        st.info("ë¨¼ì € ìƒë‹¨ì—ì„œ **ê³„ì‚°í•˜ê¸°** ë²„íŠ¼ì„ ëˆŒëŸ¬ ê³„ì‚° ìš”ì•½ì„ ìƒì„±í•˜ì„¸ìš”.")
        return

    gross = int(st.session_state.summary["gross"])
    applied = int(st.session_state.summary["applied"])
    retention_years = int(st.session_state.summary["retention_years"])
    curr_total = int(st.session_state.summary["curr_total"])
    curr_youth = int(st.session_state.summary["curr_youth"])

    years = [1, 2, 3]

    init_key = (curr_total, curr_youth)
    if "sim_df" not in st.session_state or st.session_state.get("sim_df") is None:
        st.session_state.sim_df = _pd.DataFrame(
            [{"ì—°ì°¨": yr, "ì‚¬í›„ì—°ë„ ìƒì‹œ": curr_total, "ì‚¬í›„ì—°ë„ ì²­ë…„ë“±": curr_youth} for yr in years]
        )
        st.session_state.sim_df_init_key = init_key

    reset = st.button("â†©ï¸ í‘œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”", key="btn_reset_sim", help="í˜„ì¬ ìš”ì•½ì˜ ë‹¹í•´ ì¸ì›ìœ¼ë¡œ í‘œë¥¼ ë‹¤ì‹œ ì±„ì›ë‹ˆë‹¤.")
    if reset or st.session_state.get("sim_df_init_key") != init_key:
        st.session_state.sim_df = _pd.DataFrame(
            [{"ì—°ì°¨": yr, "ì‚¬í›„ì—°ë„ ìƒì‹œ": curr_total, "ì‚¬í›„ì—°ë„ ì²­ë…„ë“±": curr_youth} for yr in years]
        )
        st.session_state.sim_df_init_key = init_key

    edited = st.data_editor(st.session_state.sim_df, num_rows="fixed", hide_index=True, key="sim_editor")
    st.session_state.sim_df = edited

    st.caption("ì—°ì°¨ë³„ ì¸ì›ì„ ì…ë ¥í•œ í›„ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì¶”ì§•ì„¸ì•¡ì„ ê³„ì‚°í•˜ì„¸ìš”.")
    if st.button("ğŸ” ì¶”ì§•ì„¸ì•¡ ê³„ì‚°í•˜ê¸°", type="primary", key="btn_compute_clawback"):
        schedule = []
        for _, row in st.session_state.sim_df.iterrows():
            yidx = int(row["ì—°ì°¨"])
            fol_total = int(row["ì‚¬í›„ì—°ë„ ìƒì‹œ"])
            fol_youth = int(row.get("ì‚¬í›„ì—°ë„ ì²­ë…„ë“±", 0))

            claw = calc_clawback(
                credit_applied=applied,
                base_headcount_at_credit=curr_total,
                headcount_in_followup_year=fol_total,
                retention_years_for_company=retention_years,
                year_index_from_credit=yidx,
                method=clawback_method,
            )
            schedule.append({"ì—°ì°¨": yidx, "ì‚¬í›„ì—°ë„ ìƒì‹œ": fol_total, "ì‚¬í›„ì—°ë„ ì²­ë…„ë“±": fol_youth, "ì¶”ì§•ì„¸ì•¡": int(claw)})

        schedule_df = _pd.DataFrame(schedule).sort_values("ì—°ì°¨").reset_index(drop=True)
        st.dataframe(schedule_df, use_container_width=True)
        total_clawback = int(schedule_df["ì¶”ì§•ì„¸ì•¡"].sum())
        st.metric("ì¶”ì§•ì„¸ì•¡ í•©ê³„", f"{total_clawback:,} ì›")

        st.session_state.last_calc = {
            "gross": gross,
            "applied": applied,
            "retention_years": retention_years,
            "company_size": size.value if hasattr(size, "value") else str(size),
            "region": region.value if hasattr(region, "value") else str(region),
            "clawback_method": clawback_method,
            "base_headcount": curr_total,
            "schedule_records": schedule_df.to_dict(orient="records"),
            "total_clawback": total_clawback,
        }
    else:
        if st.session_state.get("last_calc") and st.session_state.last_calc.get("schedule_records"):
            _df = _pd.DataFrame(st.session_state.last_calc["schedule_records"])
            st.dataframe(_df, use_container_width=True)
            tc = int(st.session_state.last_calc.get("total_clawback", _df["ì¶”ì§•ì„¸ì•¡"].sum()))
            st.metric("ì¶”ì§•ì„¸ì•¡ í•©ê³„", f"{tc:,} ì›")

from chat_utils import stream_chat


def _build_chat_context() -> str:
    """í˜„ì¬ ì…ë ¥ê°’ê³¼ ë§ˆì§€ë§‰ ê³„ì‚° ê²°ê³¼ë¥¼ ìš”ì•½í•´ ì±—ë´‡ì— ì œê³µ."""
    ci = st.session_state.get("current_inputs")
    cc = st.session_state.get("calc_context")
    lines = []
    if ci:
        lines.append(f"[í˜„ì¬ ì…ë ¥] ê¸°ì—…ê·œëª¨={ci.get('company_size')} / ì§€ì—­={ci.get('region')}")
        lines.append(f"ì „ë…„ ìƒì‹œ={ci.get('prev_total')}, ì²­ë…„ë“±={ci.get('prev_youth')} / ë‹¹í•´ ìƒì‹œ={ci.get('curr_total')}, ì²­ë…„ë“±={ci.get('curr_youth')}")
        lines.append(f"ì •ê·œì§ ì „í™˜={ci.get('converted_regular')}, ìœ¡ì•„íœ´ì§ ë³µê·€={ci.get('returned_parental')}")
        if ci.get("tax_before_credit") is not None:
            lines.append(f"ì„¸ì „ì„¸ì•¡={ci.get('tax_before_credit'):,}ì›")
        lines.append(f"ì¶”ì§•ë°©ì‹={ci.get('clawback_method')}")
    if cc:
        lines.append(f"[ìµœê·¼ ê³„ì‚° ê²°ê³¼] ì´ê³µì œì•¡={cc.get('gross_credit'):,}ì› / ì ìš©ê³µì œì•¡={cc.get('applied_credit'):,}ì› / ìœ ì§€ê¸°ê°„={cc.get('retention_years')}ë…„ / ì¶”ì§•í•©ê³„={cc.get('total_clawback'):,}ì›")
    return "\n".join(lines) if lines else ""
# .env ë¡œë“œ
# load_dotenv()  # removed unsafe call
st.divider()
st.header("ğŸ’¬ OpenAI ì±—ë´‡")
st.caption("ê³„ì‚°ê¸° ì‚¬ìš©ê³¼ ê´€ë ¨í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”. (ëª¨ë¸: gpt-4o-mini)")

# ğŸ” API í‚¤ ì…ë ¥/ì €ì¥
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = os.getenv("OPENAI_API_KEY", "")

with st.expander("ğŸ”‘ OpenAI API í‚¤ ì„¤ì •", expanded=not bool(st.session_state.openai_api_key)):
    st.info("ì•„ë˜ì— OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (í•œ ë²ˆ ì…ë ¥í•˜ë©´ ì„¸ì…˜ì´ ìœ ì§€ë©ë‹ˆë‹¤.)")
    key_input = st.text_input("API í‚¤ ì…ë ¥ (sk-ë¡œ ì‹œì‘)", type="password", value=st.session_state.openai_api_key)
    if st.button("âœ… ì ìš©í•˜ê¸°", use_container_width=True):
        st.session_state.openai_api_key = key_input.strip()
        if not st.session_state.openai_api_key.startswith("sk-"):
            st.warning("ìœ íš¨í•œ OpenAI API í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        else:
            os.environ["OPENAI_API_KEY"] = st.session_state.openai_api_key
            st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# API í‚¤ê°€ ì—†ìœ¼ë©´ ì±—ë´‡ ë¹„í™œì„±í™”
if not st.session_state.openai_api_key:
    st.warning("â›” OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ìœ„ ì…ë ¥ì°½ì— í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "system_prompt" not in st.session_state:
    st.session_state.system_prompt = "You are a helpful assistant for Korean tax credit calculator users. Reply in Korean by default."

# ì±—ë´‡ ì„¤ì •
with st.expander("âš™ï¸ ì±—ë´‡ ì„¤ì •", expanded=False):
    model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-4o-mini", "gpt-4o"], index=0)
    temperature = st.slider("ì˜¨ë„(ì°½ì˜ì„±)", 0.0, 1.0, 0.2, 0.1)
    sys_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", st.session_state.system_prompt, height=80)
    include_ctx = st.checkbox("ì§ˆë¬¸ì— ê³„ì‚° ë§¥ë½ í¬í•¨í•˜ê¸°", value=True)
    apply_pref = st.checkbox("ì„¤ì • ë°˜ì˜í•˜ê¸°", value=True)
    if apply_pref:
        st.session_state.system_prompt = sys_prompt

# ëŒ€í™” ì´ë ¥ í‘œì‹œ
for m in st.session_state.chat_history:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

with st.expander("ğŸ ë””ë²„ê·¸(ì´ë²¤íŠ¸ íƒ€ì… í™•ì¸)", expanded=False):
    if st.button("ì´ë²¤íŠ¸ íƒ€ì… ë¯¸ë¦¬ë³´ê¸°"):
        # ë¯¸ë¦¬ë³´ê¸°ìš©ìœ¼ë¡œ eventsë¥¼ êµ¬ì„±í•´ ë³´ì—¬ì¤ë‹ˆë‹¤.
        preview = []
        if st.session_state.get("system_prompt"):
            preview.append({"role":"system","type":"input_text"})
        for m in st.session_state.get("chat_history", []):
            role = m.get("role","user")
            typ = "output_text" if role == "assistant" else "input_text"
            preview.append({"role": role, "type": typ})
        st.write(preview if preview else "ì´ë ¥ ì—†ìŒ")

# ì…ë ¥ì°½
user_text = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")
if user_text:
    st.session_state.chat_history.append({"role": "user", "content": user_text})
    with st.chat_message("user"):
        st.markdown(user_text)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        acc = ""
        try:
            ctx = _build_chat_context() if include_ctx else ""
            sys_msg = st.session_state.system_prompt + ("\n\n" + ctx if ctx else "")
            for token in stream_chat(
                st.session_state.chat_history,
                system_prompt=sys_msg,
                model=model,
            ):
                acc += token
                placeholder.markdown(acc)
        except Exception as e:
            acc = f"âš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"
            placeholder.markdown(acc)

    st.session_state.chat_history.append({"role": "assistant", "content": acc})